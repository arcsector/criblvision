# CriblVision

## Upgrading to Version 3.x

Version 3.x of the CriblVision app introduces a new Cribl Stream asset lookup to replace the previous Worker Group lookup. This will cause dashboards to behave unexpectedly until the cutover to the new lookup is made. If you are upgrading from version 2.x of CriblVision then the following steps will be required to make this cutover:

1. Install version 3.x of CriblVision
2. Run the CriblVision setup age again:
    1. From the **Apps** dropdown, select **Manage Apps**
    2. Selected the **Set up** action for CriblVision
    3. Follow the instructions on the setup page
3. Run the **Populate Cribl Stream Assets Lookup** report by either:
    * Clicking the button on the landing page 
    * Clicking the link in the navigation bar
4. Double check that any alerts that were enabled are still enabled

If there are issues after completing these steps, you may need to clear your browser cache to clear cached scripts in Splunk. Clear the browser cache and follow from instructions from step 2 onwards.

If installing the app through other methods, refer to the documentation below on how to configure the app and update your configuration accordingly.

## Getting started

This Splunk app was designed as a troubleshooting tool and monitoring aid for Cribl administrators. It was created by Cribl Support Engineers to help customers troubleshoot their own Cribl deployments. There are several troubleshooting dashboards tailored to certain product areas in which support has seen the highest number of recurring issues. And while our intent is to help you troubleshoot your own Cribl deployment, this app will always be a continuous ”work in progress” and should always be used in conjunction with the Cribl monitoring console and associated views. 

### **Context is crucial**

In the ancient art of troubleshooting, context is key - whether the problem is of a technical nature, or merely one related to existence itself.

Without a clear understanding of the circumstances surrounding an issue, it becomes challenging to identify the root cause and provide an effective solution. Context provides valuable information about a specific environment, and every environment is unique; when using this app, it is wise to ask yourself the following questions:

* What is the current issue you are attempting to troubleshoot?
* Are there any recent configuration changes that were made before the issue started?
* Were there any specific user interactions that may have contributed to the start of the issue? Example: Increase in data throughput, new sources or destinations, change in architecture, etc.. 

Answers to the above questions, and many others, will help narrow down the scope of the investigation, enabling you and your team to focus their efforts on the relevant areas. Additionally, context aids in replicating the problem, as it enables Support Engineers to understand the exact conditions under which the issue occurs. Knowledge of the environment, along with all of the context on use-cases and integrations, and ensure that the troubleshooting process is efficient and accurate.

### **Configuration**

This app and its associated dashboards rely on a few components which you must configure. Note: v.2.0.0 is intended only for Cribl Stream Worker nodes and Leaders. Future releases will add dashboards and functionality for Cribl Edge deployment troubleshooting and monitoring. 

#### **Logs and Metrics**

Cribl internal logs and metrics must be enabled and forwarded to Splunk in order for all of the panels to populate with events. Refer the documentation [here](https://docs.cribl.io/stream/sources-cribl-internal/#configuring-cribl-internal-logsmetrics-as-a-datasource) for instructions on configuring this source. Be sure to configure a corresponding index and sourcetype field for logs and a corresponding index for metrics. 

#### **General Searching Macros**

This app ships with four macros which must be edited in accordance with your splunk index naming schema. For more info on configuring macros, reference Splunk’s Documentation [here](https://docs.splunk.com/Documentation/SplunkCloud/9.0.2303/Knowledge/Definesearchmacros).

<table>
  <tr>
    <th>Macro Name</th>
    <th>Description</th>
  </tr>
  <tr>
   <td>set_cribl_internal_log_index
   </td>
   <td>Set this macro definition to the index you configured cribl logs.
   </td>
  </tr>
  <tr>
   <td>set_cribl_log_sourcetype
   </td>
   <td>Set this macro definition to the sourcetype you configured for cribl logs.
   </td>
  </tr>
  <tr>
   <td>set_cribl_metrics_index
   </td>
   <td>Set this macro definition to the index you configured for cribl metrics.
   </td>
  </tr>
  <tr>
   <td>set_cribl_metrics_prefix(1)
   </td>
   <td>Change the "cribl.logstream" value before .$metric_name$ if you have changed the default namespace used for metrics on your cribl metrics internal source. 
   </td>
  </tr>
  <tr>
   <td>set_cribl_environment_field_name
   </td>
   <td>(Optional) Set this macro definition to the name of the field that specifies the environment a Cribl Stream instance belongs to.
   </td>
  </tr>
</table>

For manual configuration of the macro definitions through the CLI, append and update the following to `$SPLUNK_HOME/etc/apps/criblvision/local/macros.conf` on standalone Search Heads or `$SPLUNK_HOME/etc/shcluster/apps/criblvision/local/macros.conf` on Search Head Deployers for a Search Head Cluster:

```
[set_cribl_internal_log_index]
definition = index=cribl_logs

[set_cribl_log_sourcetype]
definition = sourcetype IN (cribl)

[set_cribl_metrics_index]
definition = index=cribl_metrics

[set_cribl_metrics_prefix(1)]
definition = cribl.logstream.$metric_name$

[set_cribl_environment_field_name]
definition = env
```

#### **Leader logs**

Some of the views in this app will require Leader logs to be forwarded on to Splunk. In distributed Cribl Stream environments, Leader logs are currently NOT sent via our internal source. You will have to install an Edge node on your Leader node and configure local log collection via a file monitor input. Configure the file monitor input to collect logs by configuring the filename allow list modal to `/opt/cribl/log/*.log`. For more information on how to deploy an Edge node, please refer to our documentation [here](https://docs.cribl.io/edge/deploy-planning). Note: When deploying the Edge node to your Leader node, we recommend having a separate fleet just for this node. Be sure to disable all other inputs on that Edge node except for file monitor inputs. 

#### **Populate Cribl Stream Asset Lookup Report**

After installing or upgrading the CriblVision application, run the **Populate Cribl Stream Asset Lookup** report to repopulate the `cribl_stream_assets` lookup. This can be done by clicking the **Populate Cribl Stream Asset Lookup** link in the navigation menu. This report is scheduled to run every hour, but can be updated to meet your requirements.

**Note:** When the report is initially run, you may see an error stating that the `cribl_stream_assets.csv` lookup file does not exist. This will not impact the search. Once the search is completed for the first time, the lookup file will be initiated and the results of the search will be written to it.

#### **Automatic Lookups**

This app uses an automatic lookup to enrich events with the Worker Group (the `worker_group` field) and the instance type (the `instnace_type` field) on events. For Leader and Single Nodes, the Worker Group value will be set to `n/a`. For more on automatic lookups, see Splunk's documentation [here](https://docs.splunk.com/Documentation/Splunk/latest/Knowledge/DefineanautomaticlookupinSplunkWeb).

When configuring an automatic lookup from the Splunk UI, ensure that the following values are set before clicking the **Save** button:

* **Lookup table:** cribl_stream_assets
* **Apply to:** sourcetype
* **named:** *Your Cribl log sourcetype **Note:** You cannot use wildcards in this definition*
* **Lookup input fields:** `host` = `host`
* **Lookup output fields:** `worker_group` = `worker_group` and `instance_type` = `instance_type`

For manual configuration of the automatic lookup definiton(s) through the CLI, append and update the following stanza to `$SPLUNK_HOME/etc/apps/criblvision/local/props.conf` on standalone Search Heads or `$SPLUNK_HOME/etc/shcluster/apps/criblvision/local/props.conf` on Search Head Deployers for a Search Head Cluster:

```
[your_sourcetype]
LOOKUP-cribl_stream_workers = cribl_stream_assets host AS host OUTPUTNEW instance_type AS instance_type worker_group AS worker_group
```

If you are using multiple sourcetypes for your internal Cribl logs and would like to use a wildcarded props definition over configuring multiple automated lookups, you can use the following stanza template:

```
[(?::){0}your_wildcarded_sourcetype]
```

### **Alerts**

This app ships with a number of disabled alerts that can be used to alert when issues in your Cribl Stream environment arise. These alerts take advantage of macros that can be utilized to tweak the alert triggers to better reflect your Cribl Stream environment. The alerts all come with default Splunk's default scheduling configured and no alert actions. The scheduling should be configured for each alert you plan to enable. For more on scheduling alerts, please reference Splunk's documentation [here](https://docs.splunk.com/Documentation/Splunk/latest/Alert/Definescheduledalerts). Fore more on configuring alert actions, please reference Splunk's documentation [here](https://docs.splunk.com/Documentation/Splunk/9.2.0/Alert/Setupalertactions).

<table>
  <tr>
    <th>Macro Name</th>
    <th>Related Alert(s)</th>
    <th>Description</th>
  </tr>
  <tr>
    <td>set_alert_ignored_destinations</td>
    <td>No Output From Destinations, Unhealthy Destinations</td>
    <td>A list of Destinations that should not trigger alerts</td>
  <tr>
  <tr>
    <td>set_alert_ignored_sources</td>
    <td>No Input From Sources, Unhealthy Sources</td>
    <td>A list of Sources that should not trigger alerts</td>
  <tr>
  <tr>
    <td>set_alert_lower_limit_unhealthy_memory_usage_mb</td>
    <td>RSS Memory Usage Within Threshold</td>
    <td>The lower limit of the threshold when alerts for memory usage (in MB) should trigger</td>
  <tr>
  <tr>
    <td>set_alert_threshold_backpressure</td>
    <td>Destinations Experiencing Backpressure</td>
    <td>The threshold of backpressure messages received (for a Worker Group + Worker) before the alert should trigger</td>
  <tr>
  <tr>
    <td>set_alert_threshold_blocked_destinations</td>
    <td>Blocked Destinations</td>
    <td>The threshold of blocked Destination messages received (for a Worker Group + Destination) before the alert should trigger</td>
  <tr>
  <tr>
    <td>set_alert_threshold_cluster_communication_errors</td>
    <td>Blocked Destinations</td>
    <td>The threshold of cluster communcation error messages received (for a Worker Group + Worker) before the alert should trigger</td>
  <tr>
  <tr>
    <td>set_alert_threshold_no_destination_thruput_pct</td>
    <td>No Output From Destinations</td>
    <td>The threshold of times a Destination has not sent any events (for a Worker Group + Destination) before the alert should trigger</td>
  <tr>
  <tr>
    <td>set_alert_threshold_no_source_thruput_pct</td>
    <td>No Input From Sources</td>
    <td>The threshold of times a Source has not received any events (for a Worker Group + Source) before the alert should trigger</td>
  <tr>
  <tr>
    <td>set_alert_threshold_unhealthy_cpu_usage_pct</td>
    <td>CPU Usage Over Threshold</td>
    <td>The threshold of times a host has reported above the unhealthy CPU percentage threshold (for a Worker Group + Worker) before the alert should trigger</td>
  <tr>
  <tr>
    <td>set_alert_threshold_unhealthy_destinations_pct</td>
    <td>Unhealthy Destinations</td>
    <td>The threshold of times a Destination has reported as being unhealthy (for a Worker Group + Destination) before the alert should trigger</td>
  <tr>
  <tr>
    <td>set_alert_threshold_unhealthy_memory_usage_mb_pct</td>
    <td>RSS Memory Usage Within Threshold</td>
    <td>The threshold of times a host has reported memory usage within the unhealthy threshold (for a Worker Group + host) before the alert should trigger</td>
  <tr>
  <tr>
    <td>set_alert_threshold_unhealthy_sources_pct</td>
    <td>Unhealthy Sources</td>
    <td>The threshold of times a Source has reported as being unhealthy (for a Worker Group + Source) before the alert should trigger</td>
  <tr>
  <tr>
    <td>set_alert_threshold_worker_process_restarts</td>
    <td>Worker Proces Restarted</td>
    <td>The threshold of times a host has reported Worker Process restarts (for a Worker Group + host) before the alert should trigger</td>
  <tr>
  <tr>
    <td>set_alert_unhealthy_cpu_usage_pct</td>
    <td>CPU Usage Over Threshold</td>
    <td>The threshold at which a host's CPU usage is deemed to be unhealthy</td>
  <tr>
  <tr>
    <td>set_alert_upper_limit_unhealthy_memory_usage_mb</td>
    <td>RSS Memory Usage Within Threshold</td>
    <td>The upper limit of the threshold when alerts for memory usage (in MB) should trigger</td>
  <tr>
</table>

## Using this app

In addition to this overview page, this app provides several views intended to aid a Cribl admin in troubleshooting and assessing the health of a Cribl deployment. Every view is equipped with a "how to use" button that reveals a description and instructions for that view when clicked. We recommend starting with the health check view and selecting a single worker node from the host dropdown.

#### **About**

* **Author:** Johan Woger 
* **Co-Authors:** Jeremy Prescott, Martin Prado, Chris Owens, and David Sheridan 
* **Honorable Mentions:**
  * George (Trey) Haraksin - For his initial ideas on thruput introspection (check out his other projects at [https://github.com/arcsector](https://github.com/arcsector)) 
  * Ben Marcus - General Testing. 
  * Brendan Dalpe - Guru of many things.
  * Brandon McCombs - General Testing.
